name: Spark Tests (Prebuilt Image)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest

    permissions:
      contents: read

    container:
      image: ghcr.io/${{ github.repository_owner }}/spark-dotnet:3.5.3-2.3.0
      options: --init
      credentials:
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GHCR_PAT }}

    env:
      TEST_CLASS: Game.Chess.Tests.Unit.ChessSparkPolicyTests
      SPARK_HOME: /opt/spark
      SPARK_VERSION: "3.5.3"
      DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
      DOTNET_CLI_TELEMETRY_OPTOUT: '1'
      DOTNET_CLI_HOME: /github/home
      NUGET_PACKAGES: /github/home/.nuget
      DOTNETBACKEND_PORT: "5567"



    steps:
      - uses: actions/checkout@v4

      - name: Show environment diagnostics
        run: |
          echo "=== Environment ==="
          whoami
          echo "HOME=$HOME"
          echo "NUGET_PACKAGES=$NUGET_PACKAGES"
          echo "DOTNET_CLI_HOME=$DOTNET_CLI_HOME"
          echo "DOTNET_WORKER_DIR=$DOTNET_WORKER_DIR"

      - name: Clear and prepare NuGet caches
        run: |
          echo "=== Clearing NuGet caches ==="
          dotnet nuget locals all --clear
          mkdir -p "$NUGET_PACKAGES"
          chmod -R 777 "$NUGET_PACKAGES"
          dotnet nuget locals all --list

      - name: Restore Spark tests
        run: |
          set -e
          cd tests/Game.Chess.Tests.Unit

          echo "=== Dotnet Info ==="
          dotnet --info

          echo
          echo "=== NuGet Sources ==="
          dotnet nuget list source

          echo
          echo "=== Restoring Project Packages (detailed logging) ==="
          dotnet restore Game.Chess.Tests.Unit.csproj --verbosity detailed --runtime linux-x64

          echo
          echo "=== Post-restore package listing ==="
          dotnet list package --include-transitive

          echo
          echo "Listing all Microsoft.Spark.dll files in NuGet cache:"
          find $NUGET_PACKAGES -type f -name "Microsoft.Spark.dll" -print

      - name: Fix Windows-style paths in NuGet cache
        shell: bash
        run: |
          echo "=== Checking for Windows-style paths in NuGet packages ==="

          # Depth-first, handle files/dirs with backslashes
          find "$NUGET_PACKAGES" -depth -name '*\\*' -print0 | while IFS= read -r -d '' f; do
            # Convert backslashes to forward slashes
            NEW_PATH=$(echo "$f" | sed 's/\\/\//g')
            # Strip trailing slashes so Linux handles files correctly
            NEW_PATH="${NEW_PATH%/}"

            if [ -d "$f" ]; then
              mkdir -p "$NEW_PATH"
              mv "$f"/* "$NEW_PATH"/ 2>/dev/null || true
              rmdir "$f" 2>/dev/null || true
              echo "Fixed directory: $f -> $NEW_PATH"
            else
              mkdir -p "$(dirname "$NEW_PATH")"
              mv "$f" "$NEW_PATH"
              echo "Fixed file: $f -> $NEW_PATH"
            fi
          done

          # Verify Microsoft.Spark.dll exists after fixing paths
          SPARK_DLL="$NUGET_PACKAGES/microsoft.spark/2.3.0/lib/netstandard2.1/Microsoft.Spark.dll"
          if [ -f "$SPARK_DLL" ]; then
            echo "âœ… Microsoft.Spark.dll confirmed at $SPARK_DLL"
          else
            echo "âŒ Still missing Microsoft.Spark.dll at $SPARK_DLL"
            exit 1
          fi


      - name: Check Spark worker DLL
        run: |
          cd tests/Game.Chess.Tests.Unit
          echo "ðŸ”§ Checking for Spark worker..."
          WORKER_DLL=$(find "$DOTNET_WORKER_DIR" -type f -name "Microsoft.Spark.dll" | head -n 1 || true)
          if [ -z "$WORKER_DLL" ]; then
            echo "âŒ Could not locate Spark worker DLL in worker dir ($DOTNET_WORKER_DIR)"
            exit 1
          fi
          echo "âœ… Found Spark worker at: $WORKER_DLL"

      - name: Verify compile-time reference visibility
        run: |
          cd tests/Game.Chess.Tests.Unit
          echo "=== Verifying reference visibility ==="
          echo "Listing Spark DLLs visible to compiler:"
          find $NUGET_PACKAGES -type f -name "Microsoft.Spark.dll" -print
          echo "Running msbuild preprocessed output for Spark references..."
          dotnet msbuild Game.Chess.Tests.Unit.csproj -pp | grep Microsoft.Spark || true

      - name: Verify file permissions
        run: |
          echo "=== Permission Check ==="
          ls -laR $NUGET_PACKAGES/microsoft.spark || true
          echo "Fixing ownership (just in case)"
          chown -R $(id -u):$(id -g) $NUGET_PACKAGES || true

      - name: Build Spark test project
        run: |
          cd tests/Game.Chess.Tests.Unit
          dotnet build --configuration Release --runtime linux-x64

      - name: Start Spark .NET Bridge and Run Tests
        shell: sh
        env:
          SPARK_HOME: /opt/spark
          DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
          DOTNETBACKEND_PORT: "5567"
        run: |
          set -euo pipefail

          cd tests/Game.Chess.Tests.Unit

          SPARK_JAR="./bin/Release/net8.0/linux-x64/microsoft-spark-3-5_2.12-2.3.0.jar"
          [ -f "$SPARK_JAR" ] || { echo "JAR not found: $SPARK_JAR"; exit 1; }

          WORKER_DLL="$DOTNET_WORKER_DIR/Microsoft.Spark.Worker/Microsoft.Spark.Worker.dll"
          [ -f "$WORKER_DLL" ] || { echo "Worker DLL not found: $WORKER_DLL"; exit 1; }

          chmod +x "$WORKER_DLL"
          chmod +x "$(dirname "$WORKER_DLL")"

          echo "Using JAR: $SPARK_JAR"
          echo "Using Worker: $WORKER_DLL"

          # Install netcat
          apt-get update -qq && apt-get install -y -qq netcat-openbsd

          # Create empty dummy ZIP to satisfy DotnetRunner
          DUMMY_ZIP="/tmp/dummy-app.zip"
          mkdir -p /tmp/dummy-app
          touch /tmp/dummy-app/Placeholder.dll
          zip -j "$DUMMY_ZIP" /tmp/dummy-app/Placeholder.dll > /dev/null
          echo "Created dummy ZIP: $DUMMY_ZIP"

          echo "Launching Spark .NET backend..."

          # Start backend in background
          nohup "$SPARK_HOME/bin/spark-submit" \
            --class org.apache.spark.deploy.dotnet.DotnetRunner \
            --master local[*] \
            --jars "$SPARK_JAR" \
            --conf spark.dotnet.backend.port=5567 \
            --conf spark.pyspark.python=/usr/bin/python3 \
            --conf spark.worker.cleanup.enabled=true \
            --conf "spark.dotnet.command=dotnet $WORKER_DLL" \
            "$SPARK_JAR" \
            "$DUMMY_ZIP" \
            > /tmp/spark-bridge.log 2>&1 &

          # Wait for backend to be ready
          echo "Waiting for backend on port 5567..."
          timeout=60
          while [ "$timeout" -gt 0 ]; do
            if nc -z 127.0.0.1 5567 2>/dev/null; then
              echo "BRIDGE READY on 5567"
              break
            fi
            sleep 1
            timeout=$((timeout - 1))
          done

          [ "$timeout" -gt 0 ] || { echo "Backend failed to start:"; cat /tmp/spark-bridge.log; exit 1; }

          # Now run the tests â€” they will connect to the backend
          echo "Running tests..."
          dotnet test \
            --configuration Release \
            --runtime linux-x64 \
            --filter "FullyQualifiedName~${{ env.TEST_CLASS }}" \
            --verbosity normal

          # Optional: show logs on failure
          echo "Spark bridge logs:"
          cat /tmp/spark-bridge.log || true