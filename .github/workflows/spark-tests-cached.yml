name: Spark Tests (Prebuilt Image)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest

    permissions:
      contents: read

    container:
      image: ghcr.io/${{ github.repository_owner }}/spark-dotnet:3.5.3-2.3.0
      options: --init
      credentials:
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GHCR_PAT }}

    env:
      TEST_CLASS: Game.Chess.Tests.Unit.ChessSparkPolicyTests
      SPARK_HOME: /opt/spark
      SPARK_VERSION: "3.5.3"
      DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
      DOTNET_CLI_TELEMETRY_OPTOUT: '1'
      DOTNET_CLI_HOME: /github/home
      NUGET_PACKAGES: /github/home/.nuget
      DOTNETBACKEND_PORT: "5567"



    steps:
      - uses: actions/checkout@v4

      - name: Show environment diagnostics
        run: |
          echo "=== Environment ==="
          whoami
          echo "HOME=$HOME"
          echo "NUGET_PACKAGES=$NUGET_PACKAGES"
          echo "DOTNET_CLI_HOME=$DOTNET_CLI_HOME"
          echo "DOTNET_WORKER_DIR=$DOTNET_WORKER_DIR"

      - name: Clear and prepare NuGet caches
        run: |
          echo "=== Clearing NuGet caches ==="
          dotnet nuget locals all --clear
          mkdir -p "$NUGET_PACKAGES"
          chmod -R 777 "$NUGET_PACKAGES"
          dotnet nuget locals all --list

      - name: Restore Spark tests
        run: |
          set -e
          cd tests/Game.Chess.Tests.Unit

          echo "=== Dotnet Info ==="
          dotnet --info

          echo
          echo "=== NuGet Sources ==="
          dotnet nuget list source

          echo
          echo "=== Restoring Project Packages (detailed logging) ==="
          dotnet restore Game.Chess.Tests.Unit.csproj --runtime linux-x64

          echo
          echo "=== Post-restore package listing ==="
          dotnet list package --include-transitive

          echo
          echo "Listing all Microsoft.Spark.dll files in NuGet cache:"
          find $NUGET_PACKAGES -type f -name "Microsoft.Spark.dll" -print

      - name: Fix Windows-style paths in NuGet cache
        shell: bash
        run: |
          echo "=== Checking for Windows-style paths in NuGet packages ==="

          # Depth-first, handle files/dirs with backslashes
          find "$NUGET_PACKAGES" -depth -name '*\\*' -print0 | while IFS= read -r -d '' f; do
            # Convert backslashes to forward slashes
            NEW_PATH=$(echo "$f" | sed 's/\\/\//g')
            # Strip trailing slashes so Linux handles files correctly
            NEW_PATH="${NEW_PATH%/}"

            if [ -d "$f" ]; then
              mkdir -p "$NEW_PATH"
              mv "$f"/* "$NEW_PATH"/ 2>/dev/null || true
              rmdir "$f" 2>/dev/null || true
              echo "Fixed directory: $f -> $NEW_PATH"
            else
              mkdir -p "$(dirname "$NEW_PATH")"
              mv "$f" "$NEW_PATH"
              echo "Fixed file: $f -> $NEW_PATH"
            fi
          done

          # Verify Microsoft.Spark.dll exists after fixing paths
          SPARK_DLL="$NUGET_PACKAGES/microsoft.spark/2.3.0/lib/netstandard2.1/Microsoft.Spark.dll"
          if [ -f "$SPARK_DLL" ]; then
            echo "âœ… Microsoft.Spark.dll confirmed at $SPARK_DLL"
          else
            echo "âŒ Still missing Microsoft.Spark.dll at $SPARK_DLL"
            exit 1
          fi


      - name: Check Spark worker DLL
        run: |
          cd tests/Game.Chess.Tests.Unit
          echo "ðŸ”§ Checking for Spark worker..."
          WORKER_DLL=$(find "$DOTNET_WORKER_DIR" -type f -name "Microsoft.Spark.dll" | head -n 1 || true)
          if [ -z "$WORKER_DLL" ]; then
            echo "âŒ Could not locate Spark worker DLL in worker dir ($DOTNET_WORKER_DIR)"
            exit 1
          fi
          echo "âœ… Found Spark worker at: $WORKER_DLL"

      - name: Verify compile-time reference visibility
        run: |
          cd tests/Game.Chess.Tests.Unit
          echo "=== Verifying reference visibility ==="
          echo "Listing Spark DLLs visible to compiler:"
          find $NUGET_PACKAGES -type f -name "Microsoft.Spark.dll" -print
          echo "Running msbuild preprocessed output for Spark references..."
          dotnet msbuild Game.Chess.Tests.Unit.csproj -pp | grep Microsoft.Spark || true

      - name: Verify file permissions
        run: |
          echo "=== Permission Check ==="
          ls -laR $NUGET_PACKAGES/microsoft.spark || true
          echo "Fixing ownership (just in case)"
          chown -R $(id -u):$(id -g) $NUGET_PACKAGES || true

      - name: Build Spark test project
        run: |
          cd tests/Game.Chess.Tests.Unit
          dotnet build --configuration Release --runtime linux-x64
          
      - name: Start Spark Backend + Run Tests
        shell: bash
        env:
          DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
          DOTNETBACKEND_PORT: "5567"
          DOTNET_WORKER_SPARK_VERSION: "2.3.0"
          PYTHON_WORKER_FACTORY_PORT: "5567"
        run: |
          set -euo pipefail

          cd tests/Game.Chess.Tests.Unit

          apt-get update -qq && apt-get install -y -qq netcat-openbsd zip

          echo "Publishing test project..."
          dotnet publish -c Release -r linux-x64 --self-contained false
          PUBLISH_DIR="bin/Release/net8.0/linux-x64/publish"
          [ -d "$PUBLISH_DIR" ] || exit 1

          SPARK_JAR="$PUBLISH_DIR/microsoft-spark-3-5_2.12-2.3.0.jar"
          [ -f "$SPARK_JAR" ] || exit 1

          WORKER_DLL="$DOTNET_WORKER_DIR/Microsoft.Spark.Worker/Microsoft.Spark.Worker.dll"
          [ -f "$WORKER_DLL" ] || exit 1
          chmod +x "$WORKER_DLL" "$(dirname "$WORKER_DLL")"

          APP_ZIP="/tmp/test-app.zip"
          (cd "$PUBLISH_DIR" && zip -r "$APP_ZIP" .) > /dev/null

          echo "Using JAR: $SPARK_JAR"
          echo "Using Worker: $WORKER_DLL"

          apt-get update -qq
          apt-get install -y -qq netcat-openbsd net-tools

          echo "Launching Spark .NET test app..."
          "$SPARK_HOME/bin/spark-submit" \
            --class org.apache.spark.deploy.dotnet.DotnetRunner \
            --master local[*] \
            --jars "$SPARK_JAR" \
            --conf spark.pyspark.python=/usr/bin/python3 \
            --conf spark.worker.cleanup.enabled=true \
            "$APP_ZIP" \
            --filter "FullyQualifiedName~${{ env.TEST_CLASS }}" \
            --verbosity normal \
            > /tmp/spark-bridge.log 2>&1 &

          #
          # ---------------------------------------------------------
          # Detect Backend Port
          # ---------------------------------------------------------
          #
          timeout=10
          PORT=""
          while [ "$timeout" -gt 0 ]; do
              PORT=$(grep -oP "DotnetRunner: Port number used by DotnetBackend is\s*\K\d+" /tmp/spark-bridge.log || true)
              if [ -n "$PORT" ]; then
                  echo "Detected backend port: $PORT"
                  break
              fi
              sleep 1
              timeout=$((timeout - 1))
          done

          [ -n "$PORT" ] || { echo "Could not detect backend port"; cat /tmp/spark-bridge.log; exit 1; }

          export DOTNETBACKEND_PORT="$PORT"
          echo "Using DOTNETBACKEND_PORT=$DOTNETBACKEND_PORT for tests"

          #
          # ---------------------------------------------------------
          # Pre-test Diagnostics
          # ---------------------------------------------------------
          #
          echo "=== Pre-test Spark diagnostics START ==="

          echo "1) Checking for Microsoft.Spark.Worker process..."
          ps -ef | grep Microsoft.Spark.Worker || true

          echo
          echo "2) Checking if port $DOTNETBACKEND_PORT is listening..."
          netstat -ltnp | grep "$DOTNETBACKEND_PORT" || echo "Port not listening"

          echo
          echo "3) Testing TCP connection to backend..."
          nc -vz 127.0.0.1 "$DOTNETBACKEND_PORT" || echo "Connection refused"

          echo
          echo "4) All listening TCP ports:"
          netstat -ltnp

          echo
          echo "5) Spark bridge log:"
          echo "*** Log Start ***"
          cat /tmp/spark-bridge.log
          echo "*** Log End ***"

          echo
          echo "6) Environment:"
          echo "DOTNETBACKEND_PORT=$DOTNETBACKEND_PORT"
          echo "DOTNET_WORKER_DIR=$DOTNET_WORKER_DIR"
          echo "SPARK_HOME=$SPARK_HOME"

          echo "=== Pre-test Spark diagnostics END ==="
          echo "WORKER READY"

          #
          # ---------------------------------------------------------
          # Run Tests
          # ---------------------------------------------------------
          #
          echo "Running tests..."
          dotnet test --no-build -c Release -r linux-x64 \
            --filter "FullyQualifiedName~${{ env.TEST_CLASS }}" \
            --verbosity normal \
            || { cat /tmp/spark-bridge.log; exit 1; }

          echo "Tests passed!"
          cat /tmp/spark-bridge.log

