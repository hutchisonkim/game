name: Spark Tests (Prebuilt Image)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest

    permissions:
      contents: read

    container:
      image: ghcr.io/${{ github.repository_owner }}/spark-dotnet:3.5.3-2.3.0
      options: --init
      credentials:
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GHCR_PAT }}

    env:
      TEST_CLASS: Game.Chess.Tests.Unit.ChessSparkPolicyTests
      SPARK_HOME: /opt/spark
      SPARK_VERSION: "3.5.3"
      DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
      DOTNET_CLI_TELEMETRY_OPTOUT: '1'
      DOTNET_CLI_HOME: /github/home
      NUGET_PACKAGES: /github/home/.nuget
      DOTNETBACKEND_PORT: "5567"



    steps:
      - uses: actions/checkout@v4

      - name: Show environment diagnostics
        run: |
          echo "=== Environment ==="
          whoami
          echo "HOME=$HOME"
          echo "NUGET_PACKAGES=$NUGET_PACKAGES"
          echo "DOTNET_CLI_HOME=$DOTNET_CLI_HOME"
          echo "DOTNET_WORKER_DIR=$DOTNET_WORKER_DIR"

      - name: Clear and prepare NuGet caches
        run: |
          echo "=== Clearing NuGet caches ==="
          dotnet nuget locals all --clear
          mkdir -p "$NUGET_PACKAGES"
          chmod -R 777 "$NUGET_PACKAGES"
          dotnet nuget locals all --list

      - name: Restore Spark tests
        run: |
          set -e
          cd tests/Game.Chess.Tests.Unit

          echo "=== Dotnet Info ==="
          dotnet --info

          echo
          echo "=== NuGet Sources ==="
          dotnet nuget list source

          echo
          echo "=== Restoring Project Packages (detailed logging) ==="
          dotnet restore Game.Chess.Tests.Unit.csproj --runtime linux-x64

          echo
          echo "=== Post-restore package listing ==="
          dotnet list package --include-transitive

          echo
          echo "Listing all Microsoft.Spark.dll files in NuGet cache:"
          find $NUGET_PACKAGES -type f -name "Microsoft.Spark.dll" -print

      - name: Fix Windows-style paths in NuGet cache
        shell: bash
        run: |
          echo "=== Checking for Windows-style paths in NuGet packages ==="

          # Depth-first, handle files/dirs with backslashes
          find "$NUGET_PACKAGES" -depth -name '*\\*' -print0 | while IFS= read -r -d '' f; do
            # Convert backslashes to forward slashes
            NEW_PATH=$(echo "$f" | sed 's/\\/\//g')
            # Strip trailing slashes so Linux handles files correctly
            NEW_PATH="${NEW_PATH%/}"

            if [ -d "$f" ]; then
              mkdir -p "$NEW_PATH"
              mv "$f"/* "$NEW_PATH"/ 2>/dev/null || true
              rmdir "$f" 2>/dev/null || true
              echo "Fixed directory: $f -> $NEW_PATH"
            else
              mkdir -p "$(dirname "$NEW_PATH")"
              mv "$f" "$NEW_PATH"
              echo "Fixed file: $f -> $NEW_PATH"
            fi
          done

          # Verify Microsoft.Spark.dll exists after fixing paths
          SPARK_DLL="$NUGET_PACKAGES/microsoft.spark/2.3.0/lib/netstandard2.1/Microsoft.Spark.dll"
          if [ -f "$SPARK_DLL" ]; then
            echo "‚úÖ Microsoft.Spark.dll confirmed at $SPARK_DLL"
          else
            echo "‚ùå Still missing Microsoft.Spark.dll at $SPARK_DLL"
            exit 1
          fi


      - name: Check Spark worker DLL
        run: |
          cd tests/Game.Chess.Tests.Unit
          echo "üîß Checking for Spark worker..."
          WORKER_DLL=$(find "$DOTNET_WORKER_DIR" -type f -name "Microsoft.Spark.dll" | head -n 1 || true)
          if [ -z "$WORKER_DLL" ]; then
            echo "‚ùå Could not locate Spark worker DLL in worker dir ($DOTNET_WORKER_DIR)"
            exit 1
          fi
          echo "‚úÖ Found Spark worker at: $WORKER_DLL"

      - name: Verify compile-time reference visibility
        run: |
          cd tests/Game.Chess.Tests.Unit
          echo "=== Verifying reference visibility ==="
          echo "Listing Spark DLLs visible to compiler:"
          find $NUGET_PACKAGES -type f -name "Microsoft.Spark.dll" -print
          echo "Running msbuild preprocessed output for Spark references..."
          dotnet msbuild Game.Chess.Tests.Unit.csproj -pp | grep Microsoft.Spark || true

      - name: Verify file permissions
        run: |
          echo "=== Permission Check ==="
          ls -laR $NUGET_PACKAGES/microsoft.spark || true
          echo "Fixing ownership (just in case)"
          chown -R $(id -u):$(id -g) $NUGET_PACKAGES || true

      - name: Build Spark test project
        run: |
          cd tests/Game.Chess.Tests.Unit
          dotnet build --configuration Release --runtime linux-x64

      - name: Start Spark Backend + Run Tests
        shell: bash
        env:
          DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
          DOTNETBACKEND_PORT: "5567"
          DOTNET_WORKER_SPARK_VERSION: "2.3.0"
          PYTHON_WORKER_FACTORY_PORT: "5567"
        run: |
          set -euo pipefail

          cd tests/Game.Chess.Tests.Unit

          echo "Publishing test project..."
          dotnet publish -c Release -r linux-x64 --self-contained false
          PUBLISH_DIR="bin/Release/net8.0/linux-x64/publish"
          [ -d "$PUBLISH_DIR" ] || exit 1

          SPARK_JAR="$PUBLISH_DIR/microsoft-spark-3-5_2.12-2.3.0.jar"
          [ -f "$SPARK_JAR" ] || exit 1

          WORKER_DLL="$DOTNET_WORKER_DIR/Microsoft.Spark.Worker/Microsoft.Spark.Worker.dll"
          [ -f "$WORKER_DLL" ] || exit 1
          chmod +x "$WORKER_DLL" && chmod +x "$(dirname "$WORKER_DLL")"

          echo "Using JAR: $SPARK_JAR"
          echo "Using Worker: $WORKER_DLL"
          
          # Install netcat and netstat (net-tools)
          apt-get update -qq && apt-get install -y -qq netcat-openbsd net-tools

          # Launch Spark backend via spark-submit
          echo "Launching bridge via spark-submit..."
          nohup "$SPARK_HOME/bin/spark-submit" \
            --class org.apache.spark.deploy.dotnet.DotnetRunner \
            --master local[*] \
            --jars "$SPARK_JAR" \
            --conf spark.dotnet.worker.factory.port=$PYTHON_WORKER_FACTORY_PORT \
            --conf spark.pyspark.python=/usr/bin/python3 \
            --conf spark.worker.cleanup.enabled=false \
            "$SPARK_JAR" \
            dotnet "$WORKER_DLL" -m pyspark.worker \
            > /tmp/spark-bridge.log 2>&1 &

          # Extract port dynamically from logs
          timeout=10
          PORT=""
          while [ "$timeout" -gt 0 ]; do
              PORT=$(grep -oP "DotnetRunner: Port number used by DotnetBackend is\s*\K\d+" /tmp/spark-bridge.log || true)
              if [ -n "$PORT" ]; then
                  echo "Detected backend port: $PORT"
                  break
              fi
              sleep 1
              timeout=$((timeout - 1))
          done
          [ -n "$PORT" ] || { echo "Could not detect backend port"; cat /tmp/spark-bridge.log; exit 1; }

          export DOTNETBACKEND_PORT=$PORT
          echo "Using DOTNETBACKEND_PORT=$DOTNETBACKEND_PORT for tests"

          echo "=== Pre-test Spark diagnostics START ==="

          # 1Ô∏è‚É£ Check if backend process is running
          echo "Checking Spark worker process..."
          ps -ef | grep Microsoft.Spark.Worker || true

          # 2Ô∏è‚É£ Confirm the port the worker claims to listen on
          echo "Checking if DOTNETBACKEND_PORT $DOTNETBACKEND_PORT is listening..."
          netstat -ltnp | grep "$DOTNETBACKEND_PORT" || echo "Port $DOTNETBACKEND_PORT not listening yet"

          # 3Ô∏è‚É£ Test TCP connection to the port
          echo "Testing TCP connection to 127.0.0.1:$DOTNETBACKEND_PORT"
          nc -vz 127.0.0.1 "$DOTNETBACKEND_PORT" || echo "Connection test failed"

          # 4Ô∏è‚É£ List all listening TCP ports
          echo "All listening TCP ports:"
          netstat -ltnp

          # 5Ô∏è‚É£ Tail the last lines of the bridge log to see startup errors
          echo "All lines of Spark bridge log:"
          echo "*** Spark Bridge Log Start ***"
          cat /tmp/spark-bridge.log
          echo "*** Spark Bridge Log End ***"

          # 6Ô∏è‚É£ Verify environment variables
          echo "DOTNETBACKEND_PORT=$DOTNETBACKEND_PORT"
          echo "DOTNET_WORKER_DIR=$DOTNET_WORKER_DIR"
          echo "SPARK_HOME=$SPARK_HOME"

          echo "=== Pre-test Spark diagnostics END ==="
          echo "WORKER READY"

          # Run tests
          echo "Running tests..."
          dotnet test --no-build -c Release -r linux-x64 \
            --filter "FullyQualifiedName~${{ env.TEST_CLASS }}" \
            --verbosity normal || { cat /tmp/spark-bridge.log; exit 1; }

          echo "Tests passed!"
          cat /tmp/spark-bridge.log
