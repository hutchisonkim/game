name: Spark Tests (Prebuilt Image)

on:
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest

    permissions:
      contents: read

    container:
      image: ghcr.io/${{ github.repository_owner }}/spark-dotnet:3.5.3-2.3.0
      options: --init
      credentials:
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GHCR_PAT }}

    env:
      TEST_CLASS: Game.Chess.Tests.Unit.ChessSparkPolicyTests
      SPARK_HOME: /opt/spark
      SPARK_VERSION: "3.5.3"
      DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
      DOTNET_CLI_TELEMETRY_OPTOUT: '1'
      DOTNET_CLI_HOME: /github/home
      NUGET_PACKAGES: /github/home/.nuget
      DOTNETBACKEND_PORT: "5567"

    steps:
      - uses: actions/checkout@v4

      - name: Clear and prepare NuGet caches
        run: |
          echo "=== Clearing NuGet caches ==="
          dotnet nuget locals all --clear
          mkdir -p "$NUGET_PACKAGES"
          chmod -R 777 "$NUGET_PACKAGES"
          dotnet nuget locals all --list

      - name: Restore Spark tests
        run: |
          echo "=== Restoring Project Packages ==="
          set -e
          cd tests/Game.Chess.Tests.Integration.Runner
          dotnet restore Game.Chess.Tests.Integration.Runner.csproj --runtime linux-x64

      - name: Fix Windows-style paths in NuGet cache
        shell: bash
        run: |
          echo "=== Checking for Windows-style paths in NuGet packages ==="

          # Depth-first, handle files/dirs with backslashes
          find "$NUGET_PACKAGES" -depth -name '*\\*' -print0 | while IFS= read -r -d '' f; do
            # Convert backslashes to forward slashes
            NEW_PATH=$(echo "$f" | sed 's/\\/\//g')
            # Strip trailing slashes so Linux handles files correctly
            NEW_PATH="${NEW_PATH%/}"

            if [ -d "$f" ]; then
              mkdir -p "$NEW_PATH"
              mv "$f"/* "$NEW_PATH"/ 2>/dev/null || true
              rmdir "$f" 2>/dev/null || true
              echo "Fixed directory: $f -> $NEW_PATH"
            else
              mkdir -p "$(dirname "$NEW_PATH")"
              mv "$f" "$NEW_PATH"
              echo "Fixed file: $f -> $NEW_PATH"
            fi
          done

          # Verify Microsoft.Spark.dll exists after fixing paths
          SPARK_DLL="$NUGET_PACKAGES/microsoft.spark/2.3.0/lib/netstandard2.1/Microsoft.Spark.dll"
          if [ -f "$SPARK_DLL" ]; then
            echo "✅ Microsoft.Spark.dll confirmed at $SPARK_DLL"
          else
            echo "❌ Still missing Microsoft.Spark.dll at $SPARK_DLL"
            exit 1
          fi

      - name: Start Spark Backend + Run Tests
        shell: bash
        env:
          DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
          DOTNETBACKEND_PORT: "5567"
          DOTNET_WORKER_SPARK_VERSION: "2.3.0"
          PYTHON_WORKER_FACTORY_PORT: "5567"
        run: |
          set -euo pipefail

          echo "Installing dependencies..."
          apt-get update -qq && apt-get install -y -qq netcat-openbsd zip net-tools

          echo "Build and publishing test project..."
          cd tests/Game.Chess.Tests.Integration.Runner
          dotnet build -f net8.0 -r linux-x64
          dotnet publish -f net8.0 -r linux-x64 -c Release --self-contained true
          PUBLISH_DIR="bin/Release/net8.0/linux-x64/publish"
          [ -d "$PUBLISH_DIR" ] || exit 1
           
          # Copy everything from the net8.0 folder to your publish dir
          cp ~/.nuget/xunit.runner.console/2.9.3/tools/net6.0/* "$PUBLISH_DIR"/

          echo "Running Spark tests via spark-submit (xUnit console runner)..."
          cd "$PUBLISH_DIR"

          export DOTNET_WORKER_DIR="$DOTNET_WORKER_DIR"
          # Run Spark in foreground, capture exit code
          "$SPARK_HOME/bin/spark-submit" \
            --class org.apache.spark.deploy.dotnet.DotnetRunner \
            --master local \
            "microsoft-spark-3-5_2.12-2.3.0.jar" \
            ./Game.Chess.Tests.Integration.Runner --filter "FullyQualifiedName~Game.Chess.Tests.Integration.ChessSparkPolicyTests"