name: "Copilot Setup Steps"

# Automatically run the setup steps when they are changed to allow for easy validation, and
# allow manual testing through the repository's "Actions" tab
on:
  workflow_dispatch:
  push:
    paths:
      - .github/workflows/copilot-setup-steps.yml
  pull_request:
    paths:
      - .github/workflows/copilot-setup-steps.yml

jobs:
  # The job MUST be called `copilot-setup-steps` or it will not be picked up by Copilot.
  copilot-setup-steps:
    runs-on: ubuntu-latest

    # Set the permissions to the lowest permissions possible needed for your steps.
    # Copilot will be given its own token for its operations.
    permissions:
      contents: read

    container:
      image: ghcr.io/${{ github.repository_owner }}/spark-dotnet:3.5.3-2.3.0
      options: --init
      credentials:
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GHCR_PAT }}

    env:
      SPARK_HOME: /opt/spark
      SPARK_VERSION: "3.5.3"
      DOTNET_WORKER_DIR: /opt/microsoft-spark-worker
      DOTNET_CLI_TELEMETRY_OPTOUT: '1'
      DOTNET_CLI_HOME: /github/home
      NUGET_PACKAGES: /github/home/.nuget
      DOTNETBACKEND_PORT: "5567"
      PYTHON_WORKER_FACTORY_PORT: "5567"
      DOTNET_WORKER_SPARK_VERSION: "2.3.0"

    steps:
      - name: Install PowerShell
        run: |
          echo "Installing PowerShell..."
          apt-get update -qq && apt-get install -y -qq wget apt-transport-https software-properties-common
          wget -q "https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/packages-microsoft-prod.deb"
          dpkg -i packages-microsoft-prod.deb
          apt-get update -qq
          apt-get install -y -qq powershell

      - name: Clear and prepare NuGet caches
        run: |
          echo "=== Clearing NuGet caches ==="
          dotnet nuget locals all --clear
          mkdir -p "$NUGET_PACKAGES"
          chmod -R 777 "$NUGET_PACKAGES"
          dotnet nuget locals all --list

      - name: Restore Spark tests
        run: |
          echo "=== Restoring Project Packages ==="
          set -e
          cd tests/Game.Chess.Tests.Integration.Runner
          dotnet restore Game.Chess.Tests.Integration.Runner.csproj --runtime linux-x64

      - name: Fix Windows-style paths in NuGet cache
        shell: bash
        run: |
          echo "=== Checking for Windows-style paths in NuGet packages ==="

          # Depth-first, handle files/dirs with backslashes
          find "$NUGET_PACKAGES" -depth -name '*\\*' -print0 | while IFS= read -r -d '' f; do
            # Convert backslashes to forward slashes
            NEW_PATH=$(echo "$f" | sed 's/\\/\//g')
            # Strip trailing slashes so Linux handles files correctly
            NEW_PATH="${NEW_PATH%/}"

            if [ -d "$f" ]; then
              mkdir -p "$NEW_PATH"
              mv "$f"/* "$NEW_PATH"/ 2>/dev/null || true
              rmdir "$f" 2>/dev/null || true
              echo "Fixed directory: $f -> $NEW_PATH"
            else
              mkdir -p "$(dirname "$NEW_PATH")"
              mv "$f" "$NEW_PATH"
              echo "Fixed file: $f -> $NEW_PATH"
            fi
          done

          # Verify Microsoft.Spark.dll exists after fixing paths
          SPARK_DLL="$NUGET_PACKAGES/microsoft.spark/2.3.0/lib/netstandard2.1/Microsoft.Spark.dll"
          if [ -f "$SPARK_DLL" ]; then
            echo "✅ Microsoft.Spark.dll confirmed at $SPARK_DLL"
          else
            echo "❌ Still missing Microsoft.Spark.dll at $SPARK_DLL"
            exit 1
          fi

      - name: Install system dependencies
        run: |
          echo "=== Installing system dependencies ==="
          apt-get update -qq
          apt-get install -y -qq netcat-openbsd zip net-tools

      - name: Build test project
        run: |
          echo "=== Building test project ==="
          cd tests/Game.Chess.Tests.Integration.Runner
          dotnet build -f net8.0 -r linux-x64
          dotnet publish -f net8.0 -r linux-x64 -c Release --self-contained true

      - name: Start Spark Runner
        shell: pwsh
        run: |
          Write-Host "Starting Spark runner..."
          pwsh ./scripts/spark-runner-start.ps1

      - name: Verify Spark environment
        run: |
          echo "=== Verifying Spark environment ==="
          echo "SPARK_HOME: $SPARK_HOME"
          echo "DOTNET_WORKER_DIR: $DOTNET_WORKER_DIR"
          ls -la "$SPARK_HOME/bin/spark-submit" || echo "spark-submit not found"
          ls -la "$DOTNET_WORKER_DIR" || echo "DOTNET_WORKER_DIR not found"
          
      - name: Environment ready for tests
        run: |
          echo "=== Environment configured for Copilot agent ==="
          echo "Spark runner is active and ready"
          echo "The agent can now run tests using: pwsh ./scripts/run-tests-with-dependencies.ps1 -Filter 'Essential=true'"

      - name: Cleanup Spark Runner
        if: always()
        shell: pwsh
        run: |
          Write-Host "=== Cleaning up Spark runner ==="
          $stopJob = Start-Job -ScriptBlock { pwsh scripts/spark-testctl.ps1 -Stop }
          if (-not (Wait-Job -Job $stopJob -Timeout 10)) {
            Stop-Job -Job $stopJob
            Write-Warning 'Stop command timed out after 10s, proceeding with aggressive cleanup...'
          } else {
            $stopJob | Receive-Job
          }
          Start-Sleep -Seconds 2
          
          Write-Host 'Calling force-kill-runners...'
          pwsh scripts/force-kill-runners.ps1
          Start-Sleep -Seconds 1
          
          Write-Host 'Killing any remaining Java processes...'
          Get-Process java -ErrorAction SilentlyContinue | ForEach-Object { 
            Write-Host "Killing Java process: $($_.Id)"
            Stop-Process -Id $_.Id -Force -ErrorAction SilentlyContinue
          }
          Start-Sleep -Seconds 1
          Write-Host 'Cleanup complete'
